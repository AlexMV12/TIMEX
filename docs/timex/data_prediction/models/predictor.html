<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>timex.data_prediction.models.predictor API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>timex.data_prediction.models.predictor</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import json
import logging
import math
import multiprocessing
import pkgutil
from functools import reduce

import pandas as pd
from pandas import DataFrame

from timex.data_prediction.transformation import transformation_factory
from timex.data_prediction.validation_performances import ValidationPerformance

log = logging.getLogger(__name__)


class SingleResult:
    &#34;&#34;&#34;
    Class for the result of a model, trained on a specific training set.

    Parameters
    ----------
    prediction : DataFrame
        Estimated prediction, using this training set
    testing_performances : ValidationPerformance
        Testing performance (`timex.data_prediction.validation_performances.ValidationPerformance`), on the validation
        set, obtained using this training set to train the model.
    &#34;&#34;&#34;

    def __init__(self, prediction: DataFrame, testing_performances: ValidationPerformance):
        self.prediction = prediction
        self.testing_performances = testing_performances


class ModelResult:
    &#34;&#34;&#34;
    Class for to collect the global results of a model trained on a time-series.

    Parameters
    ----------
    results : [SingleResult]
        List of all the results obtained using all the possible training set for this model, on the time series.
        This is useful to create plots which show how the performance vary changing the training data (e.g.
        `timex.data_visualization.functions.performance_plot`).
    characteristics : dict
        Model parameters. This dictionary collects human-readable characteristics of the model, e.g. the used number of
        validation points used, the length of the sliding training window, etc.
    best_prediction : DataFrame
        Prediction obtained using the best training window and _all_ the available points in the time-series. This is
        the prediction that users are most likely to want.
    &#34;&#34;&#34;

    def __init__(self, results: [SingleResult], characteristics: dict, best_prediction: DataFrame):
        self.results = results
        self.characteristics = characteristics
        self.best_prediction = best_prediction


class PredictionModel:
    &#34;&#34;&#34;
    Base class for every prediction model which can be used on a time series.

    Parameters
    ----------
    params : dict
        A dictionary corresponding to a TIMEX JSON configuration file.
        The various attributes, described below, will be extracted from this.
        If `params` does not contain the entry `model_parameters`, then TIMEX will attempt to load a default
        configuration parameter dictionary.
    name : str
        Class of the model.
    transformation : str, None, optional
        The class of transformation which the model should use. If not specified, the one in `params` will be used.

    Attributes
    ----------
    freq : str
        If available, the frequency of the time-series.
    test_values : int
        Number of the last points of the time-series to use for the validation set. Default 0. If this is not available
        in the configuration parameter dictionary, `test_percentage` will be used.
    test_percentage : float
        Percentage of the time-series length to used for the validation set. Default 0
    transformation : str
        Transformation to apply to the time series before using it. Default None
    prediction_lags : int
        Number of future lags for which the prediction has to be made. Default 0
    delta_training_percentage : float
        Length, in percentage of the time-series length, of the training windows.
    delta_training_values : int
        Length of the training windows, obtained by computing `delta_training_percentage * length of the time-series`.
    main_accuracy_estimator : str
        Error metric to use when deciding which prediction is better. Default: MAE.
    model_characteristics : dict
        Dictionary of values containing the main characteristics and parameters of the model. Default {}
    &#34;&#34;&#34;

    def __init__(self, params: dict, name: str, transformation: str = None) -&gt; None:
        self.name = name

        log.info(f&#34;Creating a {self.name} model...&#34;)

        if &#34;model_parameters&#34; not in params:
            log.debug(f&#34;Loading default settings...&#34;)
            parsed = pkgutil.get_data(__name__, &#34;default_prediction_parameters/&#34; + self.name + &#34;.json&#34;)
            model_parameters = json.loads(parsed)
        else:
            log.debug(f&#34;Loading user settings...&#34;)
            model_parameters = params[&#34;model_parameters&#34;]

        if &#34;test_values&#34; in model_parameters:
            self.test_values = model_parameters[&#34;test_values&#34;]
        else:
            self.test_percentage = model_parameters[&#34;test_percentage&#34;]
            self.test_values = -1

        if transformation is not None:
            self.transformation = transformation_factory(transformation)
        else:
            self.transformation = transformation_factory(model_parameters[&#34;transformation&#34;])

        self.prediction_lags = model_parameters[&#34;prediction_lags&#34;]
        self.delta_training_percentage = model_parameters[&#34;delta_training_percentage&#34;]
        self.main_accuracy_estimator = model_parameters[&#34;main_accuracy_estimator&#34;]
        self.delta_training_values = 0
        self.model_characteristics = {}

        self.freq = &#34;&#34;
        log.debug(f&#34;Finished model creation.&#34;)

    def train(self, ingested_data: DataFrame, extra_regressor: DataFrame = None):
        &#34;&#34;&#34;
        Train the model on the first column of `ingested_data`. Additional time-series, which will be used to improve
        the training in the case of a multivariate model can be passed in the `extra_regressor` DataFrame, one for each
        column.

        The predictor, after launching `train`, is ready to make predictions for the future.

        Note that this and `predict` do not split anything in training data/validation data; this is done with other
        functions, like `launch_model`.

        Parameters
        ----------
        ingested_data : DataFrame
            Training set. The entire time-series in the first column of `ingested_data` will be used for training.

        extra_regressor : DataFrame, optional, default None
            Additional time-series to use for better predictions.

        Examples
        --------
        We will use as example the `timex.data_prediction.models.prophet_predictor.FBProphetModel`, an instance of
        `Predictor`.

        &gt;&gt;&gt; param_config = {}  # This will make the predictor use default values...
        &gt;&gt;&gt; predictor = FBProphetModel(params=param_config)

        Create some training data.

        &gt;&gt;&gt; dates = pd.date_range(&#39;2000-01-01&#39;, periods=30)  # Last index is 2000-01-30
        &gt;&gt;&gt; ds = pd.DatetimeIndex(dates, freq=&#34;D&#34;)
        &gt;&gt;&gt; a = np.arange(30, 60)
        &gt;&gt;&gt; training_dataframe = DataFrame(data={&#34;a&#34;: a}, index=ds)

        Train the model.

        &gt;&gt;&gt; predictor.train(training_dataframe)
        &#34;&#34;&#34;
        pass

    def predict(self, future_dataframe: DataFrame, extra_regressor: DataFrame = None) -&gt; DataFrame:
        &#34;&#34;&#34;
        Return a DataFrame with the shape of `future_dataframe`, filled with predicted values.

        This function is used by `compute_training`; `future_dataframe` has the length of the time-series used for
        training, plus the number of desired prediction points.

        Additional `extra_regressor`, which will contain additional time-series useful to improve the prediction in case
        of multivariate models, must have the same points of `future_dataframe`.

        Parameters
        ----------
        future_dataframe : DataFrame
            DataFrame which will be filled with prediction values. This DataFrame should have the same index of the data
            used for training (plus the number of predicted values), and a column named `yhat`, which corresponds to the
            prediction that should be computed.

        extra_regressor : DataFrame, optional, default None
            DataFrame which contain optional time-series which will be used to improve the prediction. It should have
            the same shape of `future_dataframe` but with one column for each time-series. All the values should be
            present.

        Returns
        -------
        forecast : DataFrame
            DataFrame which contains the prediction computed by the model, in the column `yhat`. `forecast` may contain
            additional columns, e.g. `yhat_lower`, `yhat_upper` etc.

        Examples
        --------
        We will use as example the `timex.data_prediction.models.prophet_predictor.FBProphetModel`, an instance of
        `Predictor`.
        If the model has been trained, as shown in `predict` example, we can create a forecast.

        First, create the future dataframe which will be filled:

        &gt;&gt;&gt; future_dates = pd.date_range(&#39;2000-01-31&#39;, periods=7)
        &gt;&gt;&gt; future_ds = pd.DatetimeIndex(future_dates, freq=&#34;D&#34;)
        &gt;&gt;&gt; future_df = DataFrame(columns=[&#34;yhat&#34;], index=future_ds)
        &gt;&gt;&gt; future_df
                   yhat
        ds
        2000-01-31  NaN
        2000-02-01  NaN
        2000-02-02  NaN
        2000-02-03  NaN
        2000-02-04  NaN
        2000-02-05  NaN
        2000-02-06  NaN

        Now we can create the forecast:

        &gt;&gt;&gt; predictions = predictor.predict(future_dataframe=future_df)
        &gt;&gt;&gt; predictions
        ds
        2000-01-31    59.992592
        2000-02-01    60.992592
        2000-02-02    61.992592
        2000-02-03    62.992592
        2000-02-04    63.992592
        2000-02-05    64.992592
        2000-02-06    65.992592
        Name: yhat, dtype: float64
        &#34;&#34;&#34;
        pass

    def _compute_trainings(self, train_ts: DataFrame, test_ts: DataFrame, extra_regressors: DataFrame, max_threads: int):
        &#34;&#34;&#34;
        Compute the training of a model on a set of different training sets, of increasing length.
        `train_ts` is split in `n` different training sets, according to the length of `train_ts` and the value of
        `self.delta_training_values`. The computation is split across different processes, according to the value of
        max_threads which indicates the maximum number of usable processes.

        Parameters
        ----------
        train_ts : DataFrame
            The entire training set which can be used; it will be split in different training sets, in order to test
            which sub-training-set performs better.
        test_ts : DataFrame
            Testing set to be used to compute the models&#39; performances.
        extra_regressors : DataFrame
            Additional time-series to pass to `train` in order to improve the performances.
        max_threads : int
            Maximum number of threads to use in the training phase.

        Returns
        -------
        results : list
            List of SingleResult. Each one is the result relative to the use of a specific train set.
        &#34;&#34;&#34;
        train_sets_number = math.ceil(len(train_ts) / self.delta_training_values)
        log.info(f&#34;Model will use {train_sets_number} different training sets...&#34;)

        def c(targets: [int], _return_dict: dict, thread_number: int):
            _results = []

            for _i in range(targets[0], targets[1]):
                tr = train_ts.iloc[-(_i+1) * self.delta_training_values:]

                log.debug(f&#34;Trying with last {len(tr)} values as training set, in thread {thread_number}&#34;)

                self.train(tr.copy(), extra_regressors)

                future_df = pd.DataFrame(index=pd.date_range(freq=self.freq,
                                                             start=tr.index.values[0],
                                                             periods=len(tr) + self.test_values + self.prediction_lags),
                                         columns=[&#34;yhat&#34;], dtype=tr.iloc[:, 0].dtype)

                forecast = self.predict(future_df, extra_regressors)

                forecast.loc[:, &#39;yhat&#39;] = self.transformation.inverse(forecast[&#39;yhat&#39;])
                try:
                    forecast.loc[:, &#39;yhat_lower&#39;] = self.transformation.inverse(forecast[&#39;yhat_lower&#39;])
                    forecast.loc[:, &#39;yhat_upper&#39;] = self.transformation.inverse(forecast[&#39;yhat_upper&#39;])
                except:
                    pass

                testing_prediction = forecast.iloc[-self.prediction_lags - self.test_values:-self.prediction_lags]

                first_used_index = tr.index.values[0]

                tp = ValidationPerformance(first_used_index)
                tp.set_testing_stats(test_ts.iloc[:, 0], testing_prediction[&#34;yhat&#34;])
                _results.append(SingleResult(forecast, tp))

            _return_dict[thread_number] = _results

        manager = multiprocessing.Manager()
        return_dict = manager.dict()
        processes = []

        if self.name == &#39;LSTM&#39; or self.name == &#39;NeuralProphet&#39;:
            log.info(f&#34;LSTM/NeuralProphet model. Cant use multiprocessing.&#34;)
            return_d = {}
            distributions = [[0, train_sets_number]]
            c(distributions[0], return_d, 0)
            return return_d[0]

        if max_threads == 1:
            distributions = [[0, train_sets_number]]
            n_threads = 1
        else:
            distributions = []

            if train_sets_number % max_threads == 0:
                n_threads = max_threads
                subtraining_dim = train_sets_number // n_threads
                for i in range(0, n_threads):
                    distributions.append([i*subtraining_dim, i*subtraining_dim + subtraining_dim])
            else:
                n_threads = min(max_threads, train_sets_number)
                subtraining_dim = train_sets_number // n_threads
                for i in range(0, n_threads):
                    distributions.append([i*subtraining_dim, i*subtraining_dim+subtraining_dim])
                for k in range(0, (train_sets_number % n_threads)):
                    distributions[k][1] += 1
                    distributions[k+1::] = [ [x+1, y+1] for x, y in distributions[k+1::]]

        for i in range(0, n_threads):
            processes.append(multiprocessing.Process(target=c, args=(distributions[i], return_dict, i)))
            processes[-1].start()

        for p in processes:
            p.join()

        results = reduce(lambda x, y: x+y, [return_dict[key] for key in return_dict])

        return results

    def _compute_best_prediction(self, ingested_data: DataFrame, training_results: [SingleResult],
                                 extra_regressors: DataFrame = None):
        &#34;&#34;&#34;
        Given the ingested data and the training results, identify the best training window and compute a prediction
        using all the possible data, till the end of the series (hence, including the validation set).
        Parameters
        ----------
        ingested_data : DataFrame
            Initial time-series data, in a DataFrame. The first column of the DataFrame is the time-series.
        training_results : [SingleResult]
            List of `SingleResult` object: each one is the result of the model on a specific training-set.
        extra_regressors : DataFrame, optional, default None
            Additional time-series to use for better predictions.
        Returns
        -------
        DataFrame
            Best available prediction for this time-series, with this model.
        &#34;&#34;&#34;
        training_results.sort(key=lambda x: getattr(x.testing_performances, self.main_accuracy_estimator.upper()))
        best_starting_index = training_results[0].testing_performances.first_used_index

        training_data = ingested_data.copy().loc[best_starting_index:]

        training_data.iloc[:, 0] = self.transformation.apply(training_data.iloc[:, 0])

        self.train(training_data.copy(), extra_regressors)

        future_df = pd.DataFrame(index=pd.date_range(freq=self.freq,
                                                     start=training_data.index.values[0],
                                                     periods=len(training_data) + self.prediction_lags),
                                 columns=[&#34;yhat&#34;], dtype=training_data.iloc[:, 0].dtype)

        forecast = self.predict(future_df, extra_regressors)
        forecast.loc[:, &#39;yhat&#39;] = self.transformation.inverse(forecast[&#39;yhat&#39;])

        try:
            forecast.loc[:, &#39;yhat_lower&#39;] = self.transformation.inverse(forecast[&#39;yhat_lower&#39;])
            forecast.loc[:, &#39;yhat_upper&#39;] = self.transformation.inverse(forecast[&#39;yhat_upper&#39;])
        except:
            pass

        return forecast

    def launch_model(self, ingested_data: DataFrame, extra_regressors: DataFrame = None, max_threads: int = 1):
        &#34;&#34;&#34;
        Train the model on `ingested_data` and returns a `ModelResult` object.
        This function is at the highest possible level of abstraction to train a model on a time-series.

        Parameters
        ----------
        ingested_data : DataFrame
            DataFrame containing the historical time series value; it will be split in training and test parts.
        extra_regressors : DataFrame, optional, default None
            Additional time-series to passed to `train` in order to improve the performances.
        max_threads : int, optional, default 1
            Maximum number of threads to use in the training phase.

        Returns
        -------
        model_result : ModelResult
            `ModelResult` containing the results of the model, trained on ingested_data.

        Examples
        --------
        First, create some training data:

        &gt;&gt;&gt; dates = pd.date_range(&#39;2000-01-01&#39;, periods=30)  # Last index is 2000-01-30
        &gt;&gt;&gt; ds = pd.DatetimeIndex(dates, freq=&#34;D&#34;)
        &gt;&gt;&gt; a = np.arange(30, 60)
        &gt;&gt;&gt; timeseries_dataframe = DataFrame(data={&#34;a&#34;: a}, index=ds)

        Create the model, with default values:
        &gt;&gt;&gt; param_config = {}
        &gt;&gt;&gt; predictor = FBProphetModel(params=param_config)

        Launch the model:
        &gt;&gt;&gt; model_output = predictor.launch_model(timeseries_dataframe)

        The result is an object of class `ModelResult`: it contains the best prediction...
        &gt;&gt;&gt; model_output.best_prediction[&#39;yhat&#39;]
        ds
        2000-01-22    51.0
        2000-01-23    52.0
        2000-01-24    53.0
        2000-01-25    54.0
        2000-01-26    55.0
        2000-01-27    56.0
        2000-01-28    57.0
        2000-01-29    58.0
        2000-01-30    59.0
        2000-01-31    60.0
        2000-02-01    61.0
        2000-02-02    62.0
        2000-02-03    63.0
        2000-02-04    64.0
        2000-02-05    65.0
        2000-02-06    66.0
        2000-02-07    67.0
        2000-02-08    68.0
        2000-02-09    69.0
        Name: yhat, dtype: float64

        As well as the `characteristic` dictionary, which contains useful information on the model:
        &gt;&gt;&gt; model_output.characteristics
        {&#39;name&#39;: &#39;FBProphet&#39;, &#39;delta_training_percentage&#39;: 20, &#39;delta_training_values&#39;: 6, &#39;test_values&#39;: 3,
        &#39;transformation&#39;: &lt;timex.data_prediction.transformation.Identity object at 0x7f29214b3a00&gt;}

        The `results` attribute, instead, contains the results of the training on each of the tested sub-training-sets.
        &gt;&gt;&gt; model_output.results
        [&lt;timex.data_prediction.models.predictor.SingleResult at 0x7f28679e4a90&gt;,
         &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f28679e48b0&gt;,
         &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f286793a730&gt;,
         &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f28679e4c10&gt;,
         &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f2875cd2490&gt;]

        Each `SingleResult` has an attribute `prediction`, which contains the prediction
        on the validation set (in this case, composed by the last 3 values of `timeseries_dataframe`) and
        `testing_performances` which recaps the performance, in terms of MAE, MSE, etc. of that `SingleResult` on the
        validation set.
        &#34;&#34;&#34;
        model_characteristics = self.model_characteristics

        self.delta_training_values = int(round(len(ingested_data) * self.delta_training_percentage / 100))

        if self.test_values == -1:
            self.test_values = int(round(len(ingested_data) * (self.test_percentage / 100)))

        self.freq = pd.infer_freq(ingested_data.index)

        # We need to pass ingested data both to compute_training and compute_best_prediction, so better use copy()
        # because, otherwise, we may have side effects.
        train_ts = ingested_data.copy().iloc[:-self.test_values]
        test_ts = ingested_data.copy().iloc[-self.test_values:]

        train_ts.iloc[:, 0] = self.transformation.apply(train_ts.iloc[:, 0])

        model_training_results = self._compute_trainings(train_ts, test_ts, extra_regressors, max_threads)

        best_prediction = self._compute_best_prediction(ingested_data, model_training_results, extra_regressors)

        if extra_regressors is not None:
            model_characteristics[&#34;extra_regressors&#34;] = &#39;, &#39;.join([*extra_regressors.columns])

        model_characteristics[&#34;name&#34;] = self.name
        model_characteristics[&#34;delta_training_percentage&#34;] = self.delta_training_percentage
        model_characteristics[&#34;delta_training_values&#34;] = self.delta_training_values
        model_characteristics[&#34;test_values&#34;] = self.test_values
        model_characteristics[&#34;transformation&#34;] = self.transformation

        return ModelResult(results=model_training_results, characteristics=model_characteristics,
                           best_prediction=best_prediction)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="timex.data_prediction.models.predictor.ModelResult"><code class="flex name class">
<span>class <span class="ident">ModelResult</span></span>
<span>(</span><span>results: [<class '<a title="timex.data_prediction.models.predictor.SingleResult" href="#timex.data_prediction.models.predictor.SingleResult">SingleResult</a>'>], characteristics: dict, best_prediction: pandas.core.frame.DataFrame)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for to collect the global results of a model trained on a time-series.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>results</code></strong> :&ensp;<code>[<a title="timex.data_prediction.models.predictor.SingleResult" href="#timex.data_prediction.models.predictor.SingleResult">SingleResult</a>]</code></dt>
<dd>List of all the results obtained using all the possible training set for this model, on the time series.
This is useful to create plots which show how the performance vary changing the training data (e.g.
<code><a title="timex.data_visualization.functions.performance_plot" href="../../data_visualization/functions.html#timex.data_visualization.functions.performance_plot">performance_plot()</a></code>).</dd>
<dt><strong><code>characteristics</code></strong> :&ensp;<code>dict</code></dt>
<dd>Model parameters. This dictionary collects human-readable characteristics of the model, e.g. the used number of
validation points used, the length of the sliding training window, etc.</dd>
<dt><strong><code>best_prediction</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>Prediction obtained using the best training window and <em>all</em> the available points in the time-series. This is
the prediction that users are most likely to want.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ModelResult:
    &#34;&#34;&#34;
    Class for to collect the global results of a model trained on a time-series.

    Parameters
    ----------
    results : [SingleResult]
        List of all the results obtained using all the possible training set for this model, on the time series.
        This is useful to create plots which show how the performance vary changing the training data (e.g.
        `timex.data_visualization.functions.performance_plot`).
    characteristics : dict
        Model parameters. This dictionary collects human-readable characteristics of the model, e.g. the used number of
        validation points used, the length of the sliding training window, etc.
    best_prediction : DataFrame
        Prediction obtained using the best training window and _all_ the available points in the time-series. This is
        the prediction that users are most likely to want.
    &#34;&#34;&#34;

    def __init__(self, results: [SingleResult], characteristics: dict, best_prediction: DataFrame):
        self.results = results
        self.characteristics = characteristics
        self.best_prediction = best_prediction</code></pre>
</details>
</dd>
<dt id="timex.data_prediction.models.predictor.PredictionModel"><code class="flex name class">
<span>class <span class="ident">PredictionModel</span></span>
<span>(</span><span>params: dict, name: str, transformation: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for every prediction model which can be used on a time series.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code></dt>
<dd>A dictionary corresponding to a TIMEX JSON configuration file.
The various attributes, described below, will be extracted from this.
If <code>params</code> does not contain the entry <code>model_parameters</code>, then TIMEX will attempt to load a default
configuration parameter dictionary.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Class of the model.</dd>
<dt><strong><code>transformation</code></strong> :&ensp;<code>str, None</code>, optional</dt>
<dd>The class of transformation which the model should use. If not specified, the one in <code>params</code> will be used.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>freq</code></strong> :&ensp;<code>str</code></dt>
<dd>If available, the frequency of the time-series.</dd>
<dt><strong><code>test_values</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of the last points of the time-series to use for the validation set. Default 0. If this is not available
in the configuration parameter dictionary, <code>test_percentage</code> will be used.</dd>
<dt><strong><code>test_percentage</code></strong> :&ensp;<code>float</code></dt>
<dd>Percentage of the time-series length to used for the validation set. Default 0</dd>
<dt><strong><code>transformation</code></strong> :&ensp;<code>str</code></dt>
<dd>Transformation to apply to the time series before using it. Default None</dd>
<dt><strong><code>prediction_lags</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of future lags for which the prediction has to be made. Default 0</dd>
<dt><strong><code>delta_training_percentage</code></strong> :&ensp;<code>float</code></dt>
<dd>Length, in percentage of the time-series length, of the training windows.</dd>
<dt><strong><code>delta_training_values</code></strong> :&ensp;<code>int</code></dt>
<dd>Length of the training windows, obtained by computing <code>delta_training_percentage * length of the time-series</code>.</dd>
<dt><strong><code>main_accuracy_estimator</code></strong> :&ensp;<code>str</code></dt>
<dd>Error metric to use when deciding which prediction is better. Default: MAE.</dd>
<dt><strong><code>model_characteristics</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary of values containing the main characteristics and parameters of the model. Default {}</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PredictionModel:
    &#34;&#34;&#34;
    Base class for every prediction model which can be used on a time series.

    Parameters
    ----------
    params : dict
        A dictionary corresponding to a TIMEX JSON configuration file.
        The various attributes, described below, will be extracted from this.
        If `params` does not contain the entry `model_parameters`, then TIMEX will attempt to load a default
        configuration parameter dictionary.
    name : str
        Class of the model.
    transformation : str, None, optional
        The class of transformation which the model should use. If not specified, the one in `params` will be used.

    Attributes
    ----------
    freq : str
        If available, the frequency of the time-series.
    test_values : int
        Number of the last points of the time-series to use for the validation set. Default 0. If this is not available
        in the configuration parameter dictionary, `test_percentage` will be used.
    test_percentage : float
        Percentage of the time-series length to used for the validation set. Default 0
    transformation : str
        Transformation to apply to the time series before using it. Default None
    prediction_lags : int
        Number of future lags for which the prediction has to be made. Default 0
    delta_training_percentage : float
        Length, in percentage of the time-series length, of the training windows.
    delta_training_values : int
        Length of the training windows, obtained by computing `delta_training_percentage * length of the time-series`.
    main_accuracy_estimator : str
        Error metric to use when deciding which prediction is better. Default: MAE.
    model_characteristics : dict
        Dictionary of values containing the main characteristics and parameters of the model. Default {}
    &#34;&#34;&#34;

    def __init__(self, params: dict, name: str, transformation: str = None) -&gt; None:
        self.name = name

        log.info(f&#34;Creating a {self.name} model...&#34;)

        if &#34;model_parameters&#34; not in params:
            log.debug(f&#34;Loading default settings...&#34;)
            parsed = pkgutil.get_data(__name__, &#34;default_prediction_parameters/&#34; + self.name + &#34;.json&#34;)
            model_parameters = json.loads(parsed)
        else:
            log.debug(f&#34;Loading user settings...&#34;)
            model_parameters = params[&#34;model_parameters&#34;]

        if &#34;test_values&#34; in model_parameters:
            self.test_values = model_parameters[&#34;test_values&#34;]
        else:
            self.test_percentage = model_parameters[&#34;test_percentage&#34;]
            self.test_values = -1

        if transformation is not None:
            self.transformation = transformation_factory(transformation)
        else:
            self.transformation = transformation_factory(model_parameters[&#34;transformation&#34;])

        self.prediction_lags = model_parameters[&#34;prediction_lags&#34;]
        self.delta_training_percentage = model_parameters[&#34;delta_training_percentage&#34;]
        self.main_accuracy_estimator = model_parameters[&#34;main_accuracy_estimator&#34;]
        self.delta_training_values = 0
        self.model_characteristics = {}

        self.freq = &#34;&#34;
        log.debug(f&#34;Finished model creation.&#34;)

    def train(self, ingested_data: DataFrame, extra_regressor: DataFrame = None):
        &#34;&#34;&#34;
        Train the model on the first column of `ingested_data`. Additional time-series, which will be used to improve
        the training in the case of a multivariate model can be passed in the `extra_regressor` DataFrame, one for each
        column.

        The predictor, after launching `train`, is ready to make predictions for the future.

        Note that this and `predict` do not split anything in training data/validation data; this is done with other
        functions, like `launch_model`.

        Parameters
        ----------
        ingested_data : DataFrame
            Training set. The entire time-series in the first column of `ingested_data` will be used for training.

        extra_regressor : DataFrame, optional, default None
            Additional time-series to use for better predictions.

        Examples
        --------
        We will use as example the `timex.data_prediction.models.prophet_predictor.FBProphetModel`, an instance of
        `Predictor`.

        &gt;&gt;&gt; param_config = {}  # This will make the predictor use default values...
        &gt;&gt;&gt; predictor = FBProphetModel(params=param_config)

        Create some training data.

        &gt;&gt;&gt; dates = pd.date_range(&#39;2000-01-01&#39;, periods=30)  # Last index is 2000-01-30
        &gt;&gt;&gt; ds = pd.DatetimeIndex(dates, freq=&#34;D&#34;)
        &gt;&gt;&gt; a = np.arange(30, 60)
        &gt;&gt;&gt; training_dataframe = DataFrame(data={&#34;a&#34;: a}, index=ds)

        Train the model.

        &gt;&gt;&gt; predictor.train(training_dataframe)
        &#34;&#34;&#34;
        pass

    def predict(self, future_dataframe: DataFrame, extra_regressor: DataFrame = None) -&gt; DataFrame:
        &#34;&#34;&#34;
        Return a DataFrame with the shape of `future_dataframe`, filled with predicted values.

        This function is used by `compute_training`; `future_dataframe` has the length of the time-series used for
        training, plus the number of desired prediction points.

        Additional `extra_regressor`, which will contain additional time-series useful to improve the prediction in case
        of multivariate models, must have the same points of `future_dataframe`.

        Parameters
        ----------
        future_dataframe : DataFrame
            DataFrame which will be filled with prediction values. This DataFrame should have the same index of the data
            used for training (plus the number of predicted values), and a column named `yhat`, which corresponds to the
            prediction that should be computed.

        extra_regressor : DataFrame, optional, default None
            DataFrame which contain optional time-series which will be used to improve the prediction. It should have
            the same shape of `future_dataframe` but with one column for each time-series. All the values should be
            present.

        Returns
        -------
        forecast : DataFrame
            DataFrame which contains the prediction computed by the model, in the column `yhat`. `forecast` may contain
            additional columns, e.g. `yhat_lower`, `yhat_upper` etc.

        Examples
        --------
        We will use as example the `timex.data_prediction.models.prophet_predictor.FBProphetModel`, an instance of
        `Predictor`.
        If the model has been trained, as shown in `predict` example, we can create a forecast.

        First, create the future dataframe which will be filled:

        &gt;&gt;&gt; future_dates = pd.date_range(&#39;2000-01-31&#39;, periods=7)
        &gt;&gt;&gt; future_ds = pd.DatetimeIndex(future_dates, freq=&#34;D&#34;)
        &gt;&gt;&gt; future_df = DataFrame(columns=[&#34;yhat&#34;], index=future_ds)
        &gt;&gt;&gt; future_df
                   yhat
        ds
        2000-01-31  NaN
        2000-02-01  NaN
        2000-02-02  NaN
        2000-02-03  NaN
        2000-02-04  NaN
        2000-02-05  NaN
        2000-02-06  NaN

        Now we can create the forecast:

        &gt;&gt;&gt; predictions = predictor.predict(future_dataframe=future_df)
        &gt;&gt;&gt; predictions
        ds
        2000-01-31    59.992592
        2000-02-01    60.992592
        2000-02-02    61.992592
        2000-02-03    62.992592
        2000-02-04    63.992592
        2000-02-05    64.992592
        2000-02-06    65.992592
        Name: yhat, dtype: float64
        &#34;&#34;&#34;
        pass

    def _compute_trainings(self, train_ts: DataFrame, test_ts: DataFrame, extra_regressors: DataFrame, max_threads: int):
        &#34;&#34;&#34;
        Compute the training of a model on a set of different training sets, of increasing length.
        `train_ts` is split in `n` different training sets, according to the length of `train_ts` and the value of
        `self.delta_training_values`. The computation is split across different processes, according to the value of
        max_threads which indicates the maximum number of usable processes.

        Parameters
        ----------
        train_ts : DataFrame
            The entire training set which can be used; it will be split in different training sets, in order to test
            which sub-training-set performs better.
        test_ts : DataFrame
            Testing set to be used to compute the models&#39; performances.
        extra_regressors : DataFrame
            Additional time-series to pass to `train` in order to improve the performances.
        max_threads : int
            Maximum number of threads to use in the training phase.

        Returns
        -------
        results : list
            List of SingleResult. Each one is the result relative to the use of a specific train set.
        &#34;&#34;&#34;
        train_sets_number = math.ceil(len(train_ts) / self.delta_training_values)
        log.info(f&#34;Model will use {train_sets_number} different training sets...&#34;)

        def c(targets: [int], _return_dict: dict, thread_number: int):
            _results = []

            for _i in range(targets[0], targets[1]):
                tr = train_ts.iloc[-(_i+1) * self.delta_training_values:]

                log.debug(f&#34;Trying with last {len(tr)} values as training set, in thread {thread_number}&#34;)

                self.train(tr.copy(), extra_regressors)

                future_df = pd.DataFrame(index=pd.date_range(freq=self.freq,
                                                             start=tr.index.values[0],
                                                             periods=len(tr) + self.test_values + self.prediction_lags),
                                         columns=[&#34;yhat&#34;], dtype=tr.iloc[:, 0].dtype)

                forecast = self.predict(future_df, extra_regressors)

                forecast.loc[:, &#39;yhat&#39;] = self.transformation.inverse(forecast[&#39;yhat&#39;])
                try:
                    forecast.loc[:, &#39;yhat_lower&#39;] = self.transformation.inverse(forecast[&#39;yhat_lower&#39;])
                    forecast.loc[:, &#39;yhat_upper&#39;] = self.transformation.inverse(forecast[&#39;yhat_upper&#39;])
                except:
                    pass

                testing_prediction = forecast.iloc[-self.prediction_lags - self.test_values:-self.prediction_lags]

                first_used_index = tr.index.values[0]

                tp = ValidationPerformance(first_used_index)
                tp.set_testing_stats(test_ts.iloc[:, 0], testing_prediction[&#34;yhat&#34;])
                _results.append(SingleResult(forecast, tp))

            _return_dict[thread_number] = _results

        manager = multiprocessing.Manager()
        return_dict = manager.dict()
        processes = []

        if self.name == &#39;LSTM&#39; or self.name == &#39;NeuralProphet&#39;:
            log.info(f&#34;LSTM/NeuralProphet model. Cant use multiprocessing.&#34;)
            return_d = {}
            distributions = [[0, train_sets_number]]
            c(distributions[0], return_d, 0)
            return return_d[0]

        if max_threads == 1:
            distributions = [[0, train_sets_number]]
            n_threads = 1
        else:
            distributions = []

            if train_sets_number % max_threads == 0:
                n_threads = max_threads
                subtraining_dim = train_sets_number // n_threads
                for i in range(0, n_threads):
                    distributions.append([i*subtraining_dim, i*subtraining_dim + subtraining_dim])
            else:
                n_threads = min(max_threads, train_sets_number)
                subtraining_dim = train_sets_number // n_threads
                for i in range(0, n_threads):
                    distributions.append([i*subtraining_dim, i*subtraining_dim+subtraining_dim])
                for k in range(0, (train_sets_number % n_threads)):
                    distributions[k][1] += 1
                    distributions[k+1::] = [ [x+1, y+1] for x, y in distributions[k+1::]]

        for i in range(0, n_threads):
            processes.append(multiprocessing.Process(target=c, args=(distributions[i], return_dict, i)))
            processes[-1].start()

        for p in processes:
            p.join()

        results = reduce(lambda x, y: x+y, [return_dict[key] for key in return_dict])

        return results

    def _compute_best_prediction(self, ingested_data: DataFrame, training_results: [SingleResult],
                                 extra_regressors: DataFrame = None):
        &#34;&#34;&#34;
        Given the ingested data and the training results, identify the best training window and compute a prediction
        using all the possible data, till the end of the series (hence, including the validation set).
        Parameters
        ----------
        ingested_data : DataFrame
            Initial time-series data, in a DataFrame. The first column of the DataFrame is the time-series.
        training_results : [SingleResult]
            List of `SingleResult` object: each one is the result of the model on a specific training-set.
        extra_regressors : DataFrame, optional, default None
            Additional time-series to use for better predictions.
        Returns
        -------
        DataFrame
            Best available prediction for this time-series, with this model.
        &#34;&#34;&#34;
        training_results.sort(key=lambda x: getattr(x.testing_performances, self.main_accuracy_estimator.upper()))
        best_starting_index = training_results[0].testing_performances.first_used_index

        training_data = ingested_data.copy().loc[best_starting_index:]

        training_data.iloc[:, 0] = self.transformation.apply(training_data.iloc[:, 0])

        self.train(training_data.copy(), extra_regressors)

        future_df = pd.DataFrame(index=pd.date_range(freq=self.freq,
                                                     start=training_data.index.values[0],
                                                     periods=len(training_data) + self.prediction_lags),
                                 columns=[&#34;yhat&#34;], dtype=training_data.iloc[:, 0].dtype)

        forecast = self.predict(future_df, extra_regressors)
        forecast.loc[:, &#39;yhat&#39;] = self.transformation.inverse(forecast[&#39;yhat&#39;])

        try:
            forecast.loc[:, &#39;yhat_lower&#39;] = self.transformation.inverse(forecast[&#39;yhat_lower&#39;])
            forecast.loc[:, &#39;yhat_upper&#39;] = self.transformation.inverse(forecast[&#39;yhat_upper&#39;])
        except:
            pass

        return forecast

    def launch_model(self, ingested_data: DataFrame, extra_regressors: DataFrame = None, max_threads: int = 1):
        &#34;&#34;&#34;
        Train the model on `ingested_data` and returns a `ModelResult` object.
        This function is at the highest possible level of abstraction to train a model on a time-series.

        Parameters
        ----------
        ingested_data : DataFrame
            DataFrame containing the historical time series value; it will be split in training and test parts.
        extra_regressors : DataFrame, optional, default None
            Additional time-series to passed to `train` in order to improve the performances.
        max_threads : int, optional, default 1
            Maximum number of threads to use in the training phase.

        Returns
        -------
        model_result : ModelResult
            `ModelResult` containing the results of the model, trained on ingested_data.

        Examples
        --------
        First, create some training data:

        &gt;&gt;&gt; dates = pd.date_range(&#39;2000-01-01&#39;, periods=30)  # Last index is 2000-01-30
        &gt;&gt;&gt; ds = pd.DatetimeIndex(dates, freq=&#34;D&#34;)
        &gt;&gt;&gt; a = np.arange(30, 60)
        &gt;&gt;&gt; timeseries_dataframe = DataFrame(data={&#34;a&#34;: a}, index=ds)

        Create the model, with default values:
        &gt;&gt;&gt; param_config = {}
        &gt;&gt;&gt; predictor = FBProphetModel(params=param_config)

        Launch the model:
        &gt;&gt;&gt; model_output = predictor.launch_model(timeseries_dataframe)

        The result is an object of class `ModelResult`: it contains the best prediction...
        &gt;&gt;&gt; model_output.best_prediction[&#39;yhat&#39;]
        ds
        2000-01-22    51.0
        2000-01-23    52.0
        2000-01-24    53.0
        2000-01-25    54.0
        2000-01-26    55.0
        2000-01-27    56.0
        2000-01-28    57.0
        2000-01-29    58.0
        2000-01-30    59.0
        2000-01-31    60.0
        2000-02-01    61.0
        2000-02-02    62.0
        2000-02-03    63.0
        2000-02-04    64.0
        2000-02-05    65.0
        2000-02-06    66.0
        2000-02-07    67.0
        2000-02-08    68.0
        2000-02-09    69.0
        Name: yhat, dtype: float64

        As well as the `characteristic` dictionary, which contains useful information on the model:
        &gt;&gt;&gt; model_output.characteristics
        {&#39;name&#39;: &#39;FBProphet&#39;, &#39;delta_training_percentage&#39;: 20, &#39;delta_training_values&#39;: 6, &#39;test_values&#39;: 3,
        &#39;transformation&#39;: &lt;timex.data_prediction.transformation.Identity object at 0x7f29214b3a00&gt;}

        The `results` attribute, instead, contains the results of the training on each of the tested sub-training-sets.
        &gt;&gt;&gt; model_output.results
        [&lt;timex.data_prediction.models.predictor.SingleResult at 0x7f28679e4a90&gt;,
         &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f28679e48b0&gt;,
         &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f286793a730&gt;,
         &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f28679e4c10&gt;,
         &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f2875cd2490&gt;]

        Each `SingleResult` has an attribute `prediction`, which contains the prediction
        on the validation set (in this case, composed by the last 3 values of `timeseries_dataframe`) and
        `testing_performances` which recaps the performance, in terms of MAE, MSE, etc. of that `SingleResult` on the
        validation set.
        &#34;&#34;&#34;
        model_characteristics = self.model_characteristics

        self.delta_training_values = int(round(len(ingested_data) * self.delta_training_percentage / 100))

        if self.test_values == -1:
            self.test_values = int(round(len(ingested_data) * (self.test_percentage / 100)))

        self.freq = pd.infer_freq(ingested_data.index)

        # We need to pass ingested data both to compute_training and compute_best_prediction, so better use copy()
        # because, otherwise, we may have side effects.
        train_ts = ingested_data.copy().iloc[:-self.test_values]
        test_ts = ingested_data.copy().iloc[-self.test_values:]

        train_ts.iloc[:, 0] = self.transformation.apply(train_ts.iloc[:, 0])

        model_training_results = self._compute_trainings(train_ts, test_ts, extra_regressors, max_threads)

        best_prediction = self._compute_best_prediction(ingested_data, model_training_results, extra_regressors)

        if extra_regressors is not None:
            model_characteristics[&#34;extra_regressors&#34;] = &#39;, &#39;.join([*extra_regressors.columns])

        model_characteristics[&#34;name&#34;] = self.name
        model_characteristics[&#34;delta_training_percentage&#34;] = self.delta_training_percentage
        model_characteristics[&#34;delta_training_values&#34;] = self.delta_training_values
        model_characteristics[&#34;test_values&#34;] = self.test_values
        model_characteristics[&#34;transformation&#34;] = self.transformation

        return ModelResult(results=model_training_results, characteristics=model_characteristics,
                           best_prediction=best_prediction)</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="timex.data_prediction.models.arima_predictor.ARIMAModel" href="arima_predictor.html#timex.data_prediction.models.arima_predictor.ARIMAModel">ARIMAModel</a></li>
<li><a title="timex.data_prediction.models.lstm_predictor.LSTMModel" href="lstm_predictor.html#timex.data_prediction.models.lstm_predictor.LSTMModel">LSTMModel</a></li>
<li><a title="timex.data_prediction.models.mockup_predictor.MockUpModel" href="mockup_predictor.html#timex.data_prediction.models.mockup_predictor.MockUpModel">MockUpModel</a></li>
<li><a title="timex.data_prediction.models.neuralprophet_predictor.NeuralProphetModel" href="neuralprophet_predictor.html#timex.data_prediction.models.neuralprophet_predictor.NeuralProphetModel">NeuralProphetModel</a></li>
<li><a title="timex.data_prediction.models.prophet_predictor.FBProphetModel" href="prophet_predictor.html#timex.data_prediction.models.prophet_predictor.FBProphetModel">FBProphetModel</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="timex.data_prediction.models.predictor.PredictionModel.launch_model"><code class="name flex">
<span>def <span class="ident">launch_model</span></span>(<span>self, ingested_data: pandas.core.frame.DataFrame, extra_regressors: pandas.core.frame.DataFrame = None, max_threads: int = 1)</span>
</code></dt>
<dd>
<div class="desc"><p>Train the model on <code>ingested_data</code> and returns a <code><a title="timex.data_prediction.models.predictor.ModelResult" href="#timex.data_prediction.models.predictor.ModelResult">ModelResult</a></code> object.
This function is at the highest possible level of abstraction to train a model on a time-series.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ingested_data</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>DataFrame containing the historical time series value; it will be split in training and test parts.</dd>
<dt><strong><code>extra_regressors</code></strong> :&ensp;<code>DataFrame</code>, optional, default <code>None</code></dt>
<dd>Additional time-series to passed to <code>train</code> in order to improve the performances.</dd>
<dt><strong><code>max_threads</code></strong> :&ensp;<code>int</code>, optional, default <code>1</code></dt>
<dd>Maximum number of threads to use in the training phase.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>model_result</code></strong> :&ensp;<code><a title="timex.data_prediction.models.predictor.ModelResult" href="#timex.data_prediction.models.predictor.ModelResult">ModelResult</a></code></dt>
<dd><code><a title="timex.data_prediction.models.predictor.ModelResult" href="#timex.data_prediction.models.predictor.ModelResult">ModelResult</a></code> containing the results of the model, trained on ingested_data.</dd>
</dl>
<h2 id="examples">Examples</h2>
<p>First, create some training data:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; dates = pd.date_range('2000-01-01', periods=30)  # Last index is 2000-01-30
&gt;&gt;&gt; ds = pd.DatetimeIndex(dates, freq=&quot;D&quot;)
&gt;&gt;&gt; a = np.arange(30, 60)
&gt;&gt;&gt; timeseries_dataframe = DataFrame(data={&quot;a&quot;: a}, index=ds)
</code></pre>
<p>Create the model, with default values:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; param_config = {}
&gt;&gt;&gt; predictor = FBProphetModel(params=param_config)
</code></pre>
<p>Launch the model:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; model_output = predictor.launch_model(timeseries_dataframe)
</code></pre>
<p>The result is an object of class <code><a title="timex.data_prediction.models.predictor.ModelResult" href="#timex.data_prediction.models.predictor.ModelResult">ModelResult</a></code>: it contains the best prediction&hellip;</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; model_output.best_prediction['yhat']
ds
2000-01-22    51.0
2000-01-23    52.0
2000-01-24    53.0
2000-01-25    54.0
2000-01-26    55.0
2000-01-27    56.0
2000-01-28    57.0
2000-01-29    58.0
2000-01-30    59.0
2000-01-31    60.0
2000-02-01    61.0
2000-02-02    62.0
2000-02-03    63.0
2000-02-04    64.0
2000-02-05    65.0
2000-02-06    66.0
2000-02-07    67.0
2000-02-08    68.0
2000-02-09    69.0
Name: yhat, dtype: float64
</code></pre>
<p>As well as the <code>characteristic</code> dictionary, which contains useful information on the model:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; model_output.characteristics
{'name': 'FBProphet', 'delta_training_percentage': 20, 'delta_training_values': 6, 'test_values': 3,
'transformation': &lt;timex.data_prediction.transformation.Identity object at 0x7f29214b3a00&gt;}
</code></pre>
<p>The <code>results</code> attribute, instead, contains the results of the training on each of the tested sub-training-sets.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; model_output.results
[&lt;timex.data_prediction.models.predictor.SingleResult at 0x7f28679e4a90&gt;,
 &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f28679e48b0&gt;,
 &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f286793a730&gt;,
 &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f28679e4c10&gt;,
 &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f2875cd2490&gt;]
</code></pre>
<p>Each <code><a title="timex.data_prediction.models.predictor.SingleResult" href="#timex.data_prediction.models.predictor.SingleResult">SingleResult</a></code> has an attribute <code>prediction</code>, which contains the prediction
on the validation set (in this case, composed by the last 3 values of <code>timeseries_dataframe</code>) and
<code>testing_performances</code> which recaps the performance, in terms of MAE, MSE, etc. of that <code><a title="timex.data_prediction.models.predictor.SingleResult" href="#timex.data_prediction.models.predictor.SingleResult">SingleResult</a></code> on the
validation set.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def launch_model(self, ingested_data: DataFrame, extra_regressors: DataFrame = None, max_threads: int = 1):
    &#34;&#34;&#34;
    Train the model on `ingested_data` and returns a `ModelResult` object.
    This function is at the highest possible level of abstraction to train a model on a time-series.

    Parameters
    ----------
    ingested_data : DataFrame
        DataFrame containing the historical time series value; it will be split in training and test parts.
    extra_regressors : DataFrame, optional, default None
        Additional time-series to passed to `train` in order to improve the performances.
    max_threads : int, optional, default 1
        Maximum number of threads to use in the training phase.

    Returns
    -------
    model_result : ModelResult
        `ModelResult` containing the results of the model, trained on ingested_data.

    Examples
    --------
    First, create some training data:

    &gt;&gt;&gt; dates = pd.date_range(&#39;2000-01-01&#39;, periods=30)  # Last index is 2000-01-30
    &gt;&gt;&gt; ds = pd.DatetimeIndex(dates, freq=&#34;D&#34;)
    &gt;&gt;&gt; a = np.arange(30, 60)
    &gt;&gt;&gt; timeseries_dataframe = DataFrame(data={&#34;a&#34;: a}, index=ds)

    Create the model, with default values:
    &gt;&gt;&gt; param_config = {}
    &gt;&gt;&gt; predictor = FBProphetModel(params=param_config)

    Launch the model:
    &gt;&gt;&gt; model_output = predictor.launch_model(timeseries_dataframe)

    The result is an object of class `ModelResult`: it contains the best prediction...
    &gt;&gt;&gt; model_output.best_prediction[&#39;yhat&#39;]
    ds
    2000-01-22    51.0
    2000-01-23    52.0
    2000-01-24    53.0
    2000-01-25    54.0
    2000-01-26    55.0
    2000-01-27    56.0
    2000-01-28    57.0
    2000-01-29    58.0
    2000-01-30    59.0
    2000-01-31    60.0
    2000-02-01    61.0
    2000-02-02    62.0
    2000-02-03    63.0
    2000-02-04    64.0
    2000-02-05    65.0
    2000-02-06    66.0
    2000-02-07    67.0
    2000-02-08    68.0
    2000-02-09    69.0
    Name: yhat, dtype: float64

    As well as the `characteristic` dictionary, which contains useful information on the model:
    &gt;&gt;&gt; model_output.characteristics
    {&#39;name&#39;: &#39;FBProphet&#39;, &#39;delta_training_percentage&#39;: 20, &#39;delta_training_values&#39;: 6, &#39;test_values&#39;: 3,
    &#39;transformation&#39;: &lt;timex.data_prediction.transformation.Identity object at 0x7f29214b3a00&gt;}

    The `results` attribute, instead, contains the results of the training on each of the tested sub-training-sets.
    &gt;&gt;&gt; model_output.results
    [&lt;timex.data_prediction.models.predictor.SingleResult at 0x7f28679e4a90&gt;,
     &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f28679e48b0&gt;,
     &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f286793a730&gt;,
     &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f28679e4c10&gt;,
     &lt;timex.data_prediction.models.predictor.SingleResult at 0x7f2875cd2490&gt;]

    Each `SingleResult` has an attribute `prediction`, which contains the prediction
    on the validation set (in this case, composed by the last 3 values of `timeseries_dataframe`) and
    `testing_performances` which recaps the performance, in terms of MAE, MSE, etc. of that `SingleResult` on the
    validation set.
    &#34;&#34;&#34;
    model_characteristics = self.model_characteristics

    self.delta_training_values = int(round(len(ingested_data) * self.delta_training_percentage / 100))

    if self.test_values == -1:
        self.test_values = int(round(len(ingested_data) * (self.test_percentage / 100)))

    self.freq = pd.infer_freq(ingested_data.index)

    # We need to pass ingested data both to compute_training and compute_best_prediction, so better use copy()
    # because, otherwise, we may have side effects.
    train_ts = ingested_data.copy().iloc[:-self.test_values]
    test_ts = ingested_data.copy().iloc[-self.test_values:]

    train_ts.iloc[:, 0] = self.transformation.apply(train_ts.iloc[:, 0])

    model_training_results = self._compute_trainings(train_ts, test_ts, extra_regressors, max_threads)

    best_prediction = self._compute_best_prediction(ingested_data, model_training_results, extra_regressors)

    if extra_regressors is not None:
        model_characteristics[&#34;extra_regressors&#34;] = &#39;, &#39;.join([*extra_regressors.columns])

    model_characteristics[&#34;name&#34;] = self.name
    model_characteristics[&#34;delta_training_percentage&#34;] = self.delta_training_percentage
    model_characteristics[&#34;delta_training_values&#34;] = self.delta_training_values
    model_characteristics[&#34;test_values&#34;] = self.test_values
    model_characteristics[&#34;transformation&#34;] = self.transformation

    return ModelResult(results=model_training_results, characteristics=model_characteristics,
                       best_prediction=best_prediction)</code></pre>
</details>
</dd>
<dt id="timex.data_prediction.models.predictor.PredictionModel.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, future_dataframe: pandas.core.frame.DataFrame, extra_regressor: pandas.core.frame.DataFrame = None) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Return a DataFrame with the shape of <code>future_dataframe</code>, filled with predicted values.</p>
<p>This function is used by <code>compute_training</code>; <code>future_dataframe</code> has the length of the time-series used for
training, plus the number of desired prediction points.</p>
<p>Additional <code>extra_regressor</code>, which will contain additional time-series useful to improve the prediction in case
of multivariate models, must have the same points of <code>future_dataframe</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>future_dataframe</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>DataFrame which will be filled with prediction values. This DataFrame should have the same index of the data
used for training (plus the number of predicted values), and a column named <code>yhat</code>, which corresponds to the
prediction that should be computed.</dd>
<dt><strong><code>extra_regressor</code></strong> :&ensp;<code>DataFrame</code>, optional, default <code>None</code></dt>
<dd>DataFrame which contain optional time-series which will be used to improve the prediction. It should have
the same shape of <code>future_dataframe</code> but with one column for each time-series. All the values should be
present.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>forecast</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>DataFrame which contains the prediction computed by the model, in the column <code>yhat</code>. <code>forecast</code> may contain
additional columns, e.g. <code>yhat_lower</code>, <code>yhat_upper</code> etc.</dd>
</dl>
<h2 id="examples">Examples</h2>
<p>We will use as example the <code><a title="timex.data_prediction.models.prophet_predictor.FBProphetModel" href="prophet_predictor.html#timex.data_prediction.models.prophet_predictor.FBProphetModel">FBProphetModel</a></code>, an instance of
<code>Predictor</code>.
If the model has been trained, as shown in <code>predict</code> example, we can create a forecast.</p>
<p>First, create the future dataframe which will be filled:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; future_dates = pd.date_range('2000-01-31', periods=7)
&gt;&gt;&gt; future_ds = pd.DatetimeIndex(future_dates, freq=&quot;D&quot;)
&gt;&gt;&gt; future_df = DataFrame(columns=[&quot;yhat&quot;], index=future_ds)
&gt;&gt;&gt; future_df
           yhat
ds
2000-01-31  NaN
2000-02-01  NaN
2000-02-02  NaN
2000-02-03  NaN
2000-02-04  NaN
2000-02-05  NaN
2000-02-06  NaN
</code></pre>
<p>Now we can create the forecast:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; predictions = predictor.predict(future_dataframe=future_df)
&gt;&gt;&gt; predictions
ds
2000-01-31    59.992592
2000-02-01    60.992592
2000-02-02    61.992592
2000-02-03    62.992592
2000-02-04    63.992592
2000-02-05    64.992592
2000-02-06    65.992592
Name: yhat, dtype: float64
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, future_dataframe: DataFrame, extra_regressor: DataFrame = None) -&gt; DataFrame:
    &#34;&#34;&#34;
    Return a DataFrame with the shape of `future_dataframe`, filled with predicted values.

    This function is used by `compute_training`; `future_dataframe` has the length of the time-series used for
    training, plus the number of desired prediction points.

    Additional `extra_regressor`, which will contain additional time-series useful to improve the prediction in case
    of multivariate models, must have the same points of `future_dataframe`.

    Parameters
    ----------
    future_dataframe : DataFrame
        DataFrame which will be filled with prediction values. This DataFrame should have the same index of the data
        used for training (plus the number of predicted values), and a column named `yhat`, which corresponds to the
        prediction that should be computed.

    extra_regressor : DataFrame, optional, default None
        DataFrame which contain optional time-series which will be used to improve the prediction. It should have
        the same shape of `future_dataframe` but with one column for each time-series. All the values should be
        present.

    Returns
    -------
    forecast : DataFrame
        DataFrame which contains the prediction computed by the model, in the column `yhat`. `forecast` may contain
        additional columns, e.g. `yhat_lower`, `yhat_upper` etc.

    Examples
    --------
    We will use as example the `timex.data_prediction.models.prophet_predictor.FBProphetModel`, an instance of
    `Predictor`.
    If the model has been trained, as shown in `predict` example, we can create a forecast.

    First, create the future dataframe which will be filled:

    &gt;&gt;&gt; future_dates = pd.date_range(&#39;2000-01-31&#39;, periods=7)
    &gt;&gt;&gt; future_ds = pd.DatetimeIndex(future_dates, freq=&#34;D&#34;)
    &gt;&gt;&gt; future_df = DataFrame(columns=[&#34;yhat&#34;], index=future_ds)
    &gt;&gt;&gt; future_df
               yhat
    ds
    2000-01-31  NaN
    2000-02-01  NaN
    2000-02-02  NaN
    2000-02-03  NaN
    2000-02-04  NaN
    2000-02-05  NaN
    2000-02-06  NaN

    Now we can create the forecast:

    &gt;&gt;&gt; predictions = predictor.predict(future_dataframe=future_df)
    &gt;&gt;&gt; predictions
    ds
    2000-01-31    59.992592
    2000-02-01    60.992592
    2000-02-02    61.992592
    2000-02-03    62.992592
    2000-02-04    63.992592
    2000-02-05    64.992592
    2000-02-06    65.992592
    Name: yhat, dtype: float64
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="timex.data_prediction.models.predictor.PredictionModel.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, ingested_data: pandas.core.frame.DataFrame, extra_regressor: pandas.core.frame.DataFrame = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Train the model on the first column of <code>ingested_data</code>. Additional time-series, which will be used to improve
the training in the case of a multivariate model can be passed in the <code>extra_regressor</code> DataFrame, one for each
column.</p>
<p>The predictor, after launching <code>train</code>, is ready to make predictions for the future.</p>
<p>Note that this and <code>predict</code> do not split anything in training data/validation data; this is done with other
functions, like <code>launch_model</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ingested_data</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>Training set. The entire time-series in the first column of <code>ingested_data</code> will be used for training.</dd>
<dt><strong><code>extra_regressor</code></strong> :&ensp;<code>DataFrame</code>, optional, default <code>None</code></dt>
<dd>Additional time-series to use for better predictions.</dd>
</dl>
<h2 id="examples">Examples</h2>
<p>We will use as example the <code><a title="timex.data_prediction.models.prophet_predictor.FBProphetModel" href="prophet_predictor.html#timex.data_prediction.models.prophet_predictor.FBProphetModel">FBProphetModel</a></code>, an instance of
<code>Predictor</code>.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; param_config = {}  # This will make the predictor use default values...
&gt;&gt;&gt; predictor = FBProphetModel(params=param_config)
</code></pre>
<p>Create some training data.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; dates = pd.date_range('2000-01-01', periods=30)  # Last index is 2000-01-30
&gt;&gt;&gt; ds = pd.DatetimeIndex(dates, freq=&quot;D&quot;)
&gt;&gt;&gt; a = np.arange(30, 60)
&gt;&gt;&gt; training_dataframe = DataFrame(data={&quot;a&quot;: a}, index=ds)
</code></pre>
<p>Train the model.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; predictor.train(training_dataframe)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self, ingested_data: DataFrame, extra_regressor: DataFrame = None):
    &#34;&#34;&#34;
    Train the model on the first column of `ingested_data`. Additional time-series, which will be used to improve
    the training in the case of a multivariate model can be passed in the `extra_regressor` DataFrame, one for each
    column.

    The predictor, after launching `train`, is ready to make predictions for the future.

    Note that this and `predict` do not split anything in training data/validation data; this is done with other
    functions, like `launch_model`.

    Parameters
    ----------
    ingested_data : DataFrame
        Training set. The entire time-series in the first column of `ingested_data` will be used for training.

    extra_regressor : DataFrame, optional, default None
        Additional time-series to use for better predictions.

    Examples
    --------
    We will use as example the `timex.data_prediction.models.prophet_predictor.FBProphetModel`, an instance of
    `Predictor`.

    &gt;&gt;&gt; param_config = {}  # This will make the predictor use default values...
    &gt;&gt;&gt; predictor = FBProphetModel(params=param_config)

    Create some training data.

    &gt;&gt;&gt; dates = pd.date_range(&#39;2000-01-01&#39;, periods=30)  # Last index is 2000-01-30
    &gt;&gt;&gt; ds = pd.DatetimeIndex(dates, freq=&#34;D&#34;)
    &gt;&gt;&gt; a = np.arange(30, 60)
    &gt;&gt;&gt; training_dataframe = DataFrame(data={&#34;a&#34;: a}, index=ds)

    Train the model.

    &gt;&gt;&gt; predictor.train(training_dataframe)
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="timex.data_prediction.models.predictor.SingleResult"><code class="flex name class">
<span>class <span class="ident">SingleResult</span></span>
<span>(</span><span>prediction: pandas.core.frame.DataFrame, testing_performances: <a title="timex.data_prediction.validation_performances.ValidationPerformance" href="../validation_performances.html#timex.data_prediction.validation_performances.ValidationPerformance">ValidationPerformance</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for the result of a model, trained on a specific training set.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>prediction</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>Estimated prediction, using this training set</dd>
<dt><strong><code>testing_performances</code></strong> :&ensp;<code>ValidationPerformance</code></dt>
<dd>Testing performance (<code><a title="timex.data_prediction.validation_performances.ValidationPerformance" href="../validation_performances.html#timex.data_prediction.validation_performances.ValidationPerformance">ValidationPerformance</a></code>), on the validation
set, obtained using this training set to train the model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SingleResult:
    &#34;&#34;&#34;
    Class for the result of a model, trained on a specific training set.

    Parameters
    ----------
    prediction : DataFrame
        Estimated prediction, using this training set
    testing_performances : ValidationPerformance
        Testing performance (`timex.data_prediction.validation_performances.ValidationPerformance`), on the validation
        set, obtained using this training set to train the model.
    &#34;&#34;&#34;

    def __init__(self, prediction: DataFrame, testing_performances: ValidationPerformance):
        self.prediction = prediction
        self.testing_performances = testing_performances</code></pre>
</details>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="timex.data_prediction.models" href="index.html">timex.data_prediction.models</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="timex.data_prediction.models.predictor.ModelResult" href="#timex.data_prediction.models.predictor.ModelResult">ModelResult</a></code></h4>
</li>
<li>
<h4><code><a title="timex.data_prediction.models.predictor.PredictionModel" href="#timex.data_prediction.models.predictor.PredictionModel">PredictionModel</a></code></h4>
<ul class="">
<li><code><a title="timex.data_prediction.models.predictor.PredictionModel.launch_model" href="#timex.data_prediction.models.predictor.PredictionModel.launch_model">launch_model</a></code></li>
<li><code><a title="timex.data_prediction.models.predictor.PredictionModel.predict" href="#timex.data_prediction.models.predictor.PredictionModel.predict">predict</a></code></li>
<li><code><a title="timex.data_prediction.models.predictor.PredictionModel.train" href="#timex.data_prediction.models.predictor.PredictionModel.train">train</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="timex.data_prediction.models.predictor.SingleResult" href="#timex.data_prediction.models.predictor.SingleResult">SingleResult</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>